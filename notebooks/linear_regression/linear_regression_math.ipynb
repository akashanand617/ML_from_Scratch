{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the fundamental Mathematics behind Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Y = X\\beta + \\epsilon \\\\\n",
    "\\epsilon = Y - X\\beta \\\\\n",
    "\\epsilon^2 = (Y - X\\beta)^2 =(Y-X\\beta)^T(Y-X\\beta) \\\\\n",
    "           = Y^TY - 2\\beta^TX^TY + \\beta^TX^TX\\beta \\\\\n",
    "\n",
    "\\text{Let }Q = Y^TY - 2\\beta^TX^TY + \\beta^TX^TX\\beta \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we have to use our error function to derive the least squared error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dQ}{d\\beta} = 0 \\\\\n",
    "-2X^TY + 2X^TX\\beta = 0 \\\\\n",
    "X^TY=X^TX\\beta \\\\\n",
    "\\beta=(X^TX)^{-1}(X^TY)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This formula can serve as a basis to calculate $\\beta$ and therefore perform linear regression with our vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize gradient descent, we will have to establish our cost function J, which we can then minimize. \\\n",
    "Here we first assume $h(x) = \\sum_{j=0}^{n}{\\theta_jX_j} + b$ where we want $h(x) \\approx y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(\\theta) = \\frac{1}{2}\\sum_{j=0}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}$$\n",
    "OR, for vectorization you may use MSE:\n",
    "$$J(\\theta) = \\frac{1}{m}\\sum_{j=0}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to minimize $\\theta$, Note that $\\frac{1}{2}$ makes derivation easier minimization remains the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\theta_j=\\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta_j)$$ \n",
    "$$b = b-\\alpha\\frac{\\partial}{\\partial b}J(\\theta_j)$$\n",
    "Here, $\\alpha$ is learning rate and we take the partial derivative of the cost function with respect to $\\theta_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is specifically for j features in matrix $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial}{\\partial\\theta_j}J(\\theta_j)=\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2}(h_\\theta(x)-y)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of derivation let's assume there is only one training example -> No summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2}(h_\\theta(x)-y)^2=(2\\frac{1}{2})(h_\\theta(x)-y) (\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y)) \\\\   \n",
    "                                                             =(h_\\theta(x)-y)(\\frac{\\partial}{\\partial\\theta_j}(\\theta_0x_0 + \\theta_1x_1 +...+\\theta_nx_n + b - y)) \\\\\n",
    "                                                             =(h_\\theta(x)-y)(x_j) $$ \n",
    "We take the derivative with respect to $\\theta_j$ only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HENCE:\n",
    "$$ \\theta_j = \\theta_j - \\alpha(h_\\theta(x)-y)(x_j) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for biases:\n",
    "$$\\frac{\\partial}{\\partial b}J(\\theta_j)=\\frac{\\partial}{\\partial b}\\frac{1}{2}(h_\\theta(x)-y)^2 \\\\\n",
    "=(h_\\theta(x)-y)(\\frac{\\partial}{\\partial b}(\\theta_0x_0 + \\theta_1x_1 +...+\\theta_nx_n + b - y)) \\\\\n",
    "=(h_\\theta(x)-y)\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since this only for one training example, we say that for m training examples:\n",
    "$$\\theta_j = \\theta_j - \\alpha \\sum_{i=0}^{m}(h_\\theta(x^{(i)})-y^{(i)})(x_j) \\\\\n",
    "b = b - \\alpha \\sum_{i=0}^{m}(h_\\theta(x^{(i)})-y^{(i)})\n",
    "$$\n",
    "OR\n",
    "$$ \\theta_j = \\theta_j - \\alpha(\\frac{2}{m}) \\sum_{i=0}^{m}(h_\\theta(x^{(i)})-y^{(i)})(x_j) \\\\\n",
    "b = b - \\alpha(\\frac{2}{m}) \\sum_{i=0}^{m}(h_\\theta(x^{(i)})-y^{(i)})\n",
    "$$\n",
    "This second formula uses the MSE as a metric instead of the SSE for standardization (you could use 1/m if defining the loss function as 1/2m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out values of $\\alpha$ so that you do not overshoot, or your algorithm is too slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing this: \n",
    "We assume here that\\\n",
    "$\\theta$, y, b is (m,1) \\\n",
    "X is (m,n)\n",
    "$$\\theta = \\theta - \\alpha(\\frac{2}{m})X^T(X\\theta + b - y)\\\\\n",
    "b=b-\\alpha(\\frac{2}{m})(X\\theta + b - y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:STOCHASTIC GRADIENT DESCENT\n",
    "Above I have used batch gradient descent, stochastic uses the same concept but fits to elements 1 by 1 in a loop structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
